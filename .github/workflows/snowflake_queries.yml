name: Daily Snowflake → CSV Export

on:
  schedule:
    - cron: "15 7 * * *"   # every day at 07:15 UTC
  workflow_dispatch:         # allow manual trigger

permissions:
  contents: write

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    env:
      # Pass Snowflake credentials as environment variables for Kedro
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install -r requirements.txt --system

      - name: Run Kedro pipeline
        run: kedro run --pipeline data_transfer

      # 2️⃣ Run new telemetry_data pipeline
      - name: Run Kedro telemetry_data pipeline
        run: kedro run --pipeline telemetry_data

      # 3️⃣ Commit and push updated CSVs
      - name: Commit and push updated CSVs
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Force-add generated CSVs even if ignored
          git add -f data/02_intermediate/pypi_kedro_downloads.csv || true
          git add -f data/02_intermediate/new_kedro_users_monthly.csv || true
          git add -f data/02_intermediate/mau_kedro.csv || true
          git add -f data/02_intermediate/kedro_plugins_mau.csv || true
          git add -f data/02_intermediate/kedro_commands_mau.csv || true

          git commit -m "Update pipeline outputs [skip ci]" || echo "No changes to commit"

          # Push with built-in GITHUB_TOKEN
          git push origin HEAD:main
