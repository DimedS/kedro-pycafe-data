name: Daily Snowflake → CSV Export

on:
  schedule:
    - cron: "15 7 * * *"   # every day at 07:15 UTC
  workflow_dispatch:         # allow manual trigger

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    env:
      # Pass Snowflake credentials as environment variables for Kedro
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install -r requirements.txt --system

      - name: Run Kedro pipeline
        run: kedro run --pipeline data_transfer

      # 5️⃣  Commit and push updated CSV
      - name: Commit and push updated CSV
        if: success()
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          git config user.name "GitHub Action"
          git config user.email "actions@github.com"

          # add updated CSV, ignoring .gitignore
          git add -f data/02_intermediate/pypi_kedro_downloads.csv
          git commit -m "Update pypi_kedro_downloads.csv [skip ci]" || echo "No changes"

          # ensure remote uses your fine-grained PAT
          git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/${{ github.repository }}.git

          # push to main branch
          git push origin HEAD:main
