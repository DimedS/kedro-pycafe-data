name: Daily Snowflake → CSV Export

on:
  schedule:
    - cron: "15 7 * * *"   # every day at 07:15 UTC
  workflow_dispatch:         # allow manual trigger

permissions:
  contents: write

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    env:
      # Pass Snowflake credentials as environment variables for Kedro
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install uv
          uv pip install -r requirements.txt --system

      - name: Run Kedro pipeline
        run: kedro run --pipeline data_transfer

      # 5️⃣  Commit and push updated CSV
      - name: Commit and push updated CSV
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Force-add CSV even if ignored
          git add -f data/02_intermediate/pypi_kedro_downloads.csv
          git commit -m "Update pypi_kedro_downloads.csv [skip ci]" || echo "No changes to commit"

          # Push with built-in GITHUB_TOKEN (now has write permission)
          git push origin HEAD:main